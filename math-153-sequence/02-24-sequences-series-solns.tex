\documentclass[10pt]{amsart}

%Packages in use
\usepackage{fullpage, hyperref, vipul, enumerate}

%Title details
\title{Take-home class quiz solutions: due February 24: Sequences and series, miscellaneous stuff}
\author{Math 153, Section 55 (Vipul Naik)}
%List of new commands

\begin{document}
\maketitle

\section{Performance review}

The score distribution was as follows:

\begin{itemize}
\item Score of $3$: $1$ person
\item Score of $6$: $1$ person
\item Score of $7$: $3$ people
\item Score of $8$: $3$ people
\item Score of $9$: $2$ people
\item Score of $13$: $1$ person
\end{itemize}

The mean score was $7.73$. The question wise answers and performance
summary are below:

\begin{enumerate}
\item Option (B): $9$ people
\item Option (B): $11$ people
\item Option (B): $8$ people
\item Option (B): $8$ people
\item Option (A): $6$ people
\item Option (B): $2$ people
\item Option (C): $5$ people
\item Option (B): $4$ people
\item Option (D): $5$ people
\item Option (E): $6$ people
\item Option (E): $4$ people
\item Option (A): $5$ people
\item Option (D): $2$ people
\item Option (D): $6$ people
\item Option (C): $4$ people
\end{enumerate}

\section{Solutions}

\begin{enumerate}
\item {\em Forward difference operators and partial sums}: Recall that
  for a function $g: \N \to \R$, the forward difference operator of
  $g$, denoted $\Delta g$, is defined as the function $(\Delta g)(n) =
  g(n+1) - g(n)$. Suppose we have two functions $f,g: \N \to \R$ such
  that $g(n) = \sum_{k=1}^n f(k)$. What is the relationship between
  $\Delta g$ and $f$? {\em This is a discrete version of the
  fundamental theorem of calculus.}

  \begin{enumerate}[(A)]
  \item $(\Delta g)(n) = f(n)$ for all $n \in \N$
  \item $(\Delta g)(n) = f(n + 1)$ for all $n \in \N$
  \item $(\Delta g)(n + 1) = f(n)$ for all $n \in \N$
  \item $(\Delta g)(n) = f(n + 2)$ for all $n \in \N$
  \item $(\Delta g)(n + 2) = f(n)$ for all $n \in \N$
  \end{enumerate}

  {\em Answer}: Option (B)

  {\em Explanation}: We have:

  $$g(n+1) = \sum_{k=1}^{n+1} f(k) = f(1) + f(2) + \dots + f(n) + f(n + 1)$$

  and:

  $$g(n) = \sum_{k=1}^n f(k) = f(1) + f(2) + \dots + f(n)$$

  Subtracting, we obtain:

  $$(\Delta g)(n) = f(n + 1)$$

  {\em Performance review}: $9$ people got this correct. $1$ each
  chose (A) and (C).
\item Which of the following is the correct definition of $\lim_{x \to
  \infty} f(x) = L$ for $L$ a finite number?

  \begin{enumerate}[(A)]
  \item For every $\epsilon > 0$ there exists $a \in \R$ such that if
    $0 < |x - L| < \epsilon$ then $f(x) > a$.
  \item For every $\epsilon > 0$ there exists $a \in \R$ such that if
    $x > a$ then $|f(x) - L| < \epsilon$.
  \item For every $a \in \R$ there exists $\epsilon > 0$ such that if
    $x > a$ then $|f(x) - L| < \epsilon$.
  \item For every $a \in \R$ there exists $\epsilon > 0$ such that if
    $0 < |x - L| < \epsilon$ then $f(x) > a$.
  \item There exists $a \in \R$ and $\epsilon > 0$ such that if $x >
    a$ then $|f(x) - L| < \epsilon$.
  \end{enumerate}

  {\em Answer}: Option (B)

  {\em Explanation}: Straightforward unraveling of the definition.

  {\em Performance review}: $11$ people got this.

  {\em Historical note (last year)}: $21$ out of $25$ people got this
  correct. $1$ person each chose options (A), (C), (D), and (E).

\item {\em Horizontal asymptote and limit of derivative}: Suppose
  $\lim_{x \to \infty} f'(x)$ is finite. Which of the following is
  true (be careful about $f$ versus $f'$ when reading the choices)?
  \begin{enumerate}[(A)]
  \item If $\lim_{x \to \infty} f'(x)$ is zero, then $\lim_{x \to
    \infty} f(x)$ is finite.
  \item If $\lim_{x \to \infty} f(x)$ is finite, then $\lim_{x \to
    \infty} f'(x)$ is zero.
  \item If $\lim_{x \to \infty} f(x)$ is finite, then $\lim_{x \to
    \infty} f(x)$ is zero.
  \item All of the above.
  \item None of the above.
  \end{enumerate}

  {\em Answer}: Option (B)

  {\em Explanation}: If $f$ is going to a finite value, its derivative
  cannot have a nonzero limit, because that would mean a roughly
  linear behavior. Since the derivative has a limit, it must go to
  zero.

  Note that {\em if we were not explicitly told that the derivative
    has a limit}, then option (E) would be the correct option.

  Note that option (A) is wrong, because we can construct
  counterexamples such as $\ln$ and the square root function, where
  the derivative of the function goes to zero but the function does
  not have a finite limit at the point.

  {\em Performance review}: $8$ out of $11$ people got this
  correct. $2$ chose (A), $1$ had an ambiguous entry.

  {\em Historical note (last year)}: $8$ out of $25$ people got this
  correct. $10$ people chose (A), $5$ people chose (E), and $2$ people
  chose (C).

  {\em Action point}: Make sure you understand this and get it right
  in the future!

\item {\em Convergent sequence and limit of forward difference
  operator}: Suppose $f: \N \to \R$ is a function (so we can think of
  it as a sequence). Which of the following is true? Here $(\Delta
  f)(n) =f(n+1) - f(n)$.

  \begin{enumerate}[(A)]
  \item If $\lim_{n \to \infty} (\Delta f)(n)$ is zero, then $\lim_{n \to
    \infty} f(n)$ is finite.
  \item If $\lim_{n \to \infty} f(n)$ is finite, then $\lim_{n \to
    \infty} (\Delta f)(n)$ is zero.
  \item If $\lim_{n \to \infty} f(n)$ is finite, then $\lim_{n \to
    \infty} f(n)$ is zero.
  \item All of the above.
  \item None of the above.
  \end{enumerate}

  {\em Answer}: Option (B)

  {\em Explanation}: If $\lim_{n \to \infty} f(n) = L$, then for every
  $\epsilon > 0$ there exists a large enough value $n_0$ such that for
  $n > n_0$, we have $|f(n) - L| < \epsilon$. Using the triangle
  inequality, we get that $|f(n + 1) - f(n)| < 2\epsilon$, so $\lim_{n
  \to \infty} (\Delta f)(n) = 0$.

  This is pretty much the sequence analogue of the preceding question,
  and the square root and logarithm functions provide counterexamples
  to (A). The key difference between the sequence version and the
  continuous version is that in the latter case, we need to explicitly
  assume that the derivative converges and {\em then} can show it must
  go to zero, but in the sequence case, convergence does not need to
  be assumed.

  {\em Performance review}: $8$ out of $11$ got this correct. $3$
  chose (A).

\item {\em Function iteration converges at infinity}: Suppose $(a_n)$
  is a sequence whose terms are given by the relation $a_n =
  f(a_{n-1})$, with $a_1$ specified separately and $f$ is a continuous
  function on $\R$. Further, suppose we know that $\lim_{n \to \infty}
  a_n = L$ for some finite $L$. What can we conclude is true about
  $L$?

  \begin{enumerate}[(A)]
  \item $f(L) = L$
  \item $f(L) = 0$
  \item $f'(L) = L$
  \item $f'(L) = 0$
  \item $f''(L) = 0$
  \end{enumerate}

  {\em Answer}: Option (A)

  {\em Explanation}: This was one of your homework problems (Advanced
  3 on HW 7).

  {\em Performance review}: $6$ out of $11$ people got this
  correct. $4$ chose (D), $1$ chose (C).

\item {\em Equilibrium at infinity}: Suppose a function $y$ of time
  $t$ satisfies the differential equation $y' = f(y)$ for all time
  $t$, where $f$ is a continuous function on $\R$. Further, suppose we
  know that $\lim_{t \to \infty} y = L$ for some finite $L$. What can
  we conclude is true about $L$?  {\em Note: Although the question is
  conceptually similar to the preceding question, you have to reason
  about the question differently.}
  \begin{enumerate}[(A)]
  \item $f(L) = L$
  \item $f(L) = 0$
  \item $f'(L) = L$
  \item $f'(L) = 0$
  \item $f''(L) = 0$
  \end{enumerate}

  {\em Answer}: Option (B)

  {\em Explanation}: We in particular have that $\lim_{t \to \infty}
  y' = \lim_{t \to \infty} f(y) = f(L)$, hence $\lim_{t \to \infty}
  y'$ is finite. Applying the previous question, we obtain that this
  limit must be $0$, so we get $f(L) = 0$.

  {\em Performance review}: $2$ got this correct, $4$ chose (D), $3$
  chose (C), and $2$ chose (E).

  {\em Historical note (last year)}: $11$ out of $25$ people got this
  correct. $6$ people chose (D), $5$ people chose (C), and $3$ people
  chose (A).

  Those who chose option (A) probably used the discrete analogy. While
  the analogy works qualitatively, the conclusion was wrongly
  applied. Here, $f$ is not the function being iterated (which is the
  discrete setup) but rather, it is the derivative of a changing
  value. When the value becomes constant, $f$ must become zero.

\item A sequence $a_n$ is found to satisfy the recurrence $a_{n+1} =
  2a_n(1 - a_n)$. Assume that $a_1$ is strictly between $0$ and
  $1$. What can we say about the sequence $(a_n)$?
  \begin{enumerate}[(A)]
  \item It is monotonic non-increasing, and its limit is $0$.
  \item It is monotonic non-decreasing, and its limit is $1$.
  \item From $a_2$ onward, it is monotonic non-decreasing, and its
    limit is $1/2$.
  \item From $a_2$ onward, it is monotonic non-increasing, and its
    limit is $1/2$.
  \item It is either monotonic non-decreasing or monotonic
    non-increasing everywhere, and its limit is $1/2$.
  \end{enumerate}

  {\em Answer}: Option (C)

  {\em Explanation}: Whatever the value of $a_1$, $0 < a_2 \le
  1/2$. Once we are in this interval, we see that $f(x) \ge x$ for all
  $x$ in the interval, and $f(x)$ is also in the interval. Thus, the
  sequence is monotonic non-decreasing from $a_2$ onward, and is
  bounded from above by $1/2$. It converges to its greatest lower
  bound, which we know must be fixed under $f$. Hence, it must
  converge to $1/2$, which is the only positive number fixed under
  $f$.

  (More details can be worked out using algebra/calculus).

  {\em Performance review}: $5$ out of $11$ got this correct. $4$
  chose (D), $1$ each chose (B) and (E).

  {\em Historical note (last year)}: $8$ out of $25$ people got this
  correct. $8$ people chose (D), $4$ chose (A), $3$ chose (E), $2$
  chose (B).

\item Suppose $f$ is a continuous function on $\R$ and $(a_n)$ is a
  sequence satisfying the recurrence $f(a_n) = a_{n+1}$ for all
  $n$. Further, suppose the limit of the $a_n$s for odd $n$ is $L$ and
  the limit of the $a_n$s for even $n$ is $M$. What can we say about
  $L$ and $M$?
  \begin{enumerate}[(A)]
  \item $f(L) = L$ and $f(M) = M$
  \item $f(L) = M$ and $f(M) = L$
  \item $f(L) = f(M) = 0$
  \item $f'(L) = f'(M) = 0$
  \item $f'(L) = M$ and $f'(M) = L$
  \end{enumerate}

  {\em Answer}: Option (B)

  {\em Explanation}: Each even indexed term is obtained by applying
  $f$ to the preceding odd indexed term, and each odd indexed term is
  obtained by applying $f$ to the preceding even indexed term. Taking
  appropriate limits, we get the desired conclusion.

  {\em Performance review}: $4$ out of $11$ people got this
  correct. $3$ chose (A), $2$ chose (D), $1$ each chose (C) and (E).

  {\em Historical note (last year)}: $7$ out of $25$ people got this
  correct. $8$ chose (A), $4$ each chose (C) and (D), $1$ chose (E),
  and $1$ left the question blank.

  {\em Action point}: After understanding the solution, you should not
  forget the idea!

\item Consider a function $f$ on the natural numbers defined as
  follows: $f(m) = m/2$ if $m$ is even, and $f(m) = 3m + 1$ if $m$ is
  odd. Consider a sequence where $a_1$ is a natural number and we
  define $a_n := f(a_{n-1})$. It is conjectured (see {\em Collatz
  conjecture}) that $(a_n)$ is eventually periodic, regardless of the
  starting point, and that there is only one possibility for the
  eventual periodic fragment. Which of the following can be the
  eventual periodic fragment?

  \begin{enumerate}[(A)]
  \item $(1,2,3)$
  \item $(1,3,2)$
  \item $(1,2,4)$
  \item $(1,4,2)$
  \item $(1,3,4)$
  \end{enumerate}

  {\em Answer}: Option (D)

  {\em Explanation}: Can be seen by applying the definition.

  {\em Performance review}: $5$ out of $11$ people to this
  correct. $3$ chose (C), $2$ chose (E), $1$ chose (A).

  {\em Historical note (last year)}: $13$ out
  of $25$ people got this correct. $5$ chose (C), $3$ chose (B), $2$
  chose (A), $1$ chose (E), and $1$ left the question blank.

  Those who chose (C) probably overlooked the issue of the cyclic
  ordering of elements within the periodic sequence.

  {\em Extra credit}: Prove the Collatz conjecture.

\item For which of the following properties $p$ of sequences of real
  numbers does $p$ equal {\em eventually} $p$?
  \begin{enumerate}[(A)]
  \item Monotonicity
  \item Periodicity
  \item Being a polynomial sequence (i.e., given by a polynomial function)
  \item Being a constant sequence
  \item Boundedness
  \end{enumerate}

  {\em Answer}: Option (E)

  {\em Explanation}: If a sequence is eventually bounded, then that
  means that excluding the first few terms gives a bounded
  sequence. But throwing back these finitely many terms, which have a
  fixed maximum and minimum, will still give a bounded sequence.

  {\em Performance review}: $6$ out of $11$ people got this
  correct. $2$ each chose (A) and (D), $1$ chose (C).

  {\em Historical note (last year)}: $10$ out of $25$ people got this
  correct. $5$ each chose (A) and (D), $2$ each chose (B) and (C), and
  $1$ left the question blank.

  {\em Action point}: You should definitely understand, appreciate,
  and remember this one!

  The remaining questions are based on a rule which we call the {\em
  degree difference rule}. This states the following. Consider a
  rational function $p(x)/q(x)$, and suppose $a \in \R$ is such that
  $q$ has no roots in $[a,\infty)$. Then, the improper integral
  $\int_a^\infty \frac{p(x)}{q(x)} \, dx$ is finite if and only if the
  degree of $q$ minus the degree of $p$ is {\em at least} two, or in
  other words, is strictly greater than one. The same rule applies to
  $\int_{-\infty}^\infty \frac{p(x)}{q(x)} \, dx$ if $q$ has no zero.

  The degree difference rule has a slight variation: we can apply it
  to situation where $p$ and $q$ are not quite polynomials, but rather
  their growth rates are of the same order as that of some polynomial
  or power function. For instance, $(x^2 + 1)^{3/2}$ has ``degree''
  three with this more liberal interpretation. {\em In this more
  liberal interpretation, we require that the degree difference (which
  could now be a non-integer), be strictly greater than one. For
  instance, a degree difference of $3/2$ means that the integral
  converges.}

  Consider a probability distribution on $\R$ with density function
  $f$. In particular, this means that $\int_{-\infty}^\infty f(x) \,
  dx = 1$. Further, assume that $f$ has mean zero and is an even
  function, i.e., the probability distribution is symmetric about
  zero.

  The {\em mean deviation} of the distribution is defined as
  $\int_{-\infty}^\infty |x|f(x) \, dx$. On account of the fact that
  $f$ is an even function, this can be rewritten as $2
  \int_0^\infty xf(x) \, dx$.

  The {\em standard deviation} of the distribution, denoted $\sigma$, of $f$ is defined as
  $\sqrt{\int_{-\infty}^\infty x^2 f(x) \, dx}$.

  The {\em kurtosis} of the distribution is defined as $-3 +
  (\int_{-\infty}^\infty x^4 f(x) \, dx)/\sigma^4$. Note that the
  kurtosis does not make sense if the standard deviation is infinite.

\item Consider the distribution with density function $f(x):=
  (x^2+1)^{-1}/\pi$. (We divide by $\pi$ so that the integral on
  $(-\infty,\infty)$ is $1$). Which of the following is true?

  \begin{enumerate}[(A)]
  \item The mean deviation is finite but the standard deviation is infinite.
  \item The standard deviation and kurtosis are finite, but the mean deviation is infinite.
  \item The standard deviation, mean deviation, and kurtosis are all finite.
  \item The standard deviation and mean deviation are finite, but the kurtosis is infinite.
  \item The standard deviation and mean deviation are both infinite.
  \end{enumerate}

  {\em Answer}: Option (E)

  {\em Explanation}: Ignoring constants, the integrals that need to be
  computed for the mean deviation and standard deviation are
  respectively:

  $$\int_0^\infty \frac{x \, dx}{x^2 + 1}$$

  and

  $$\int_{-\infty}^\infty \frac{x^2 \, dx}{x^2 + 1}$$

  The degree difference for mean deviation is $2 - 1 = 1$ and the
  degree difference for standard deviation is $2 - 2 = 0$.  By the
  degree difference rule, both these integrals diverge. It is also
  possible to compute the integrals explicitly and check that they
  diverge.

  {\em Performance review}: $4$ out of $11$ people got this
  correct. $2$ each chose (A), (B), and (C), $1$ chose (D).

\item Consider the distribution with density function $f(x):=
  (x^2+1)^{-3/2}/2$. (We divide by $2$ so that the integral on
  $(-\infty,\infty)$ is $1$). Which of the following is true?

  \begin{enumerate}[(A)]
  \item The mean deviation is finite but the standard deviation is infinite.
  \item The standard deviation and kurtosis are finite, but the mean deviation is infinite.
  \item The standard deviation, mean deviation, and kurtosis are all finite.
  \item The standard deviation and mean deviation are finite, but the kurtosis is infinite.
  \item The standard deviation and mean deviation are both infinite.
  \end{enumerate}

  {\em Answer}: Option (A)

  {\em Explanation}: Ignoring constants, the integrals that need to be
  computed for the mean deviation and standard deviation are
  respectively:

  $$\int_0^\infty \frac{x \, dx}{(x^2 + 1)^{3/2}}$$

  and

  $$\int_{-\infty}^\infty \frac{x^2 \, dx}{(x^2 + 1)^{3/2}}$$

  The ``degree'' of the denominator is $3$ (obtained as $2 \times
  (3/2) = 3$).

  The degree difference for the mean deviation is $3 - 1 = 2$. Thus,
  the integral for the mean deviation satisfies the degree difference
  rule, hence it converges. 

  The degree difference for the standard deviatin is $3 - 2 =
  1$. Hence, the integral for the standard deviation does {\em not}
  satisfy the degree difference rule, hence it does not converge.

  {\em Bonus observation}: If we were to actually calculate the mean
  deviation, we would get:

  $$\frac{2}{2} \int_0^\infty \frac{x \, dx}{(x^2 + 1)^{3/2}}$$

  This simplifies to:

  $$\left[\frac{-1}{\sqrt{x^2 + 1}}\right]_0^\infty$$

  This further simplifies to $1$.

  {\em Performance review}: $5$ out of $11$ got this correct. $4$
  chose (B), $1$ each chose (C) and (E).

\item Consider the distribution with density function $f(x):=
  (x^2+1)^{-2}/(\pi/2)$. (We divide by $\pi/2$ so that the integral on
  $(-\infty,\infty)$ is $1$). Which of the following is true?

  \begin{enumerate}[(A)]
  \item The mean deviation is finite but the standard deviation is infinite.
  \item The standard deviation and kurtosis are finite, but the mean deviation is infinite.
  \item The standard deviation, mean deviation, and kurtosis are all finite.
  \item The standard deviation and mean deviation are finite, but the kurtosis is infinite.
  \item The standard deviation and mean deviation are both infinite.
  \end{enumerate}

  {\em Answer}: Option (D)

  {\em Explanation}: Ignoring constants, the integrals that need to be
  computed for the mean deviation and standard deviation are
  respectively:

  $$\int_0^\infty \frac{x \, dx}{(x^2 + 1)^2}$$

  and

  $$\int_{-\infty}^\infty \frac{x^2 \, dx}{(x^2 + 1)^2}$$

  The degree of the denominator is $4$. 

  The degree difference for the mean deviation integral is $4 - 1 =
  3$. Thus, the integral for the mean deviation satisfies the degree
  difference rule, hence it converges.

  The degree difference for the standard deviation is $4 - 2 =
  2$. Thus, the integral for the standard deviation converges as well.

  Finally, we consider the integral for the kurtosis:

  $$\int_{-\infty}^\infty \frac{x^4}{(x^2 + 1)^2} \, dx$$

  The degree difference is $4 - 4 = 0$, so this integral does not
  converge.

  {\em Bonus observation}: The mean deviation is $2/\pi$ and the
  standard deviation is $1$.

  If we were to actually calculate the mean deviation, we would get:

  $$\frac{2}{\pi/2} \int_0^\infty \frac{x \, dx}{(x^2 + 1)^2}$$

  This simplifies to:

  $$\frac{2}{\pi}\left[\frac{-1}{x^2 + 1}\right]_0^\infty$$

  This further simplifies to $2/\pi$. The mean deviation is thus $2/\pi$.

  For the standard deviation, we need to compute:

  $$\sqrt{\frac{1}{\pi/2}\int_{-\infty}^\infty \frac{x^2 \, dx}{(x^2 + 1)^2}}$$

  The integral simplifies to $\pi/2$, so the standard deviation is
  $\sqrt{1} = 1$.

  {\em Performance review}: $2$ out of $11$ got this correct. $7$
  chose (C), $2$ chose (B).
\item Consider the distribution with density function $f(x):=
  (x^2+1)^{-5/2}/(4/3)$. (We divide by $4/3$ so that the integral on
  $(-\infty,\infty)$ is $1$). Which of the following is true?

  \begin{enumerate}[(A)]
  \item The mean deviation is finite but the standard deviation is infinite.
  \item The standard deviation and kurtosis are finite, but the mean deviation is infinite.
  \item The standard deviation, mean deviation, and kurtosis are all finite.
  \item The standard deviation and mean deviation are finite, but the kurtosis is infinite.
  \item The standard deviation and mean deviation are both infinite.
  \end{enumerate}

  {\em Answer}: Option (D)

  {\em Explnation}: With reasoning similar to the previous questions,
  the degree differences for the mean deviation, standard deviation,
  and kurtosis are respectively $5 - 1 = 4$, $5 - 2 = 3$, and $5 - 4 =
  1$. By the degree difference rule, the first two exist, but the
  third does not.

  {\em Performance review}: $6$ out of $11$ got this correct. $2$each
  chose (A) and (E), $1$ chose (B).

\item Consider the distribution with density function $f(x):=
  (x^2+1)^{-3}/(3\pi/8)$. (We divide by $3\pi/8$ so that the integral on
  $(-\infty,\infty)$ is $1$). Which of the following is true?

  \begin{enumerate}[(A)]
  \item The mean deviation is finite but the standard deviation is infinite.
  \item The standard deviation and kurtosis are finite, but the mean deviation is infinite.
  \item The standard deviation, mean deviation, and kurtosis are all finite.
  \item The standard deviation and mean deviation are finite, but the kurtosis is infinite.
  \item The standard deviation and mean deviation are both infinite.
  \end{enumerate}

  {\em Answer}: Option (C)

  {\em Explanation}: With reasoning similar to the previous questions,
  the degree differences for the mean deviation, standard deviation,
  and kurtosis are respectively $6 - 1 = 5$, $6 - 2 = 4$, and $6 - 4 =
  2$. By the degree difference rule, all the integrals converge.

  {\em Performance review}: $4$ out of $11$ people got this
  correct. $4$ chose (B), $2$ chose (D), $1$ chose (E).
\end{enumerate}
\end{document}