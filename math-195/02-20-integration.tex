\documentclass[10pt]{amsart}

%Packages in use
\usepackage{fullpage, hyperref, vipul, enumerate}

%Title details
\title{Take-home class quiz: due Wednesday February 20: Integration techniques (one variable)}
\author{Math 195, Section 59 (Vipul Naik)}
%List of new commands

\begin{document}
\maketitle

Your name (print clearly in capital letters): $\underline{\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad}$

In the questions below, we say that a function is {\em expressible in
terms of elementary functions} or {\em elementarily expressible} if it
can be expressed in terms of polynomial functions, rational functions,
radicals, exponents, logarithms, trigonometric functions and inverse
trigonometric functions using pointwise combinations, compositions,
and piecewise definitions. We say that a function is {\em elementarily
integrable} if it has an elementarily expressible antiderivative.

Note that if a function is elementarily expressible, so is its
derivative on the domain of definition.

We say that a function $f$ is $k$ times elementarily integrable if
there is an elementarily expressible function $g$ such that $f$ is the
$k^{th}$ derivative of $g$.

We say that the integrals of two functions are {\em equivalent up to
elementary functions} if an antiderivative for one function can be
expressed using an antiderivative for the other function and
elementary function, again piecing them together using pointwise
combination, composition, and piecewise definitions.

{\bf YOU ARE FREE TO DISCUSS ALL QUESTIONS, BUT PLEASE ONLY ENTER
FINAL ANSWER OPTIONS THAT YOU PERSONALLY ENDORSE. DO NOT ENGAGE IN
GROUPTHINK.}

\begin{enumerate}

\item Suppose $F$ and $G$ are continuously differentiable functions on
  all of $\R$ (i.e., both $F'$ and $G'$ are continuous). Which of the
  following is {\bf not necessarily true}? Please see Option (E)
  before answering.

  \begin{enumerate}[(A)]
  \item If $F'(x) = G'(x)$ for all integers $x$, then $F - G$ is a
    constant function when restricted to integers, i.e., it takes the
    same value at all integers.
  \item If $F'(x) = G'(x)$ for all numbers $x$ that are not integers,
    then $F - G$ is a constant function when restricted to the set of
    numbers $x$ that are not integers.
  \item If $F'(x) = G'(x)$ for all rational numbers $x$, then $F - G$
    is a constant function when restricted to the set of rational
    numbers.
  \item If $F'(x) = G'(x)$ for all irrational numbers $x$, then $F -
    G$ is a constant function when restricted to the set of irrational
    numbers.
  \item None of the above, i.e., they are all necessarily true.
  \end{enumerate}

  \vspace{0.05in}
  Your answer: $\underline{\qquad\qquad\qquad\qquad\qquad\qquad\qquad}$
  \vspace{0.05in}

\item Suppose $F$ and $G$ are two functions defined on $\R$ and $k$ is
  a natural number such that the $k^{th}$ derivatives of $F$ and $G$
  exist and are equal on all of $\R$. Then, $F - G$ must be a
  polynomial function. What is the {\bf maximum possible degree} of $F
  - G$?  (Note: Assume constant polynomials to have degree zero)

  \begin{enumerate}[(A)]
  \item $k - 2$
  \item $k - 1$
  \item $k$
  \item $k + 1$
  \item There is no bound in terms of $k$.
  \end{enumerate}

  \vspace{0.05in}
  Your answer: $\underline{\qquad\qquad\qquad\qquad\qquad\qquad\qquad}$
  \vspace{0.05in}

\item Suppose $f$ is a continuous function on $\R$. Clearly, $f$ has
  antiderivatives on $\R$. For all but one of the following
  conditions, it is possible to guarantee, without any further
  information about $f$, that there exists an antiderivative $F$
  satisfying that condition. {\bf Identify the exceptional condition}
  (i.e., the condition that it may not always be possible to satisfy).

  \begin{enumerate}[(A)]
  \item $F(1) = F(0)$.
  \item $F(1) + F(0) = 0$.
  \item $F(1) + F(0) = 1$.
  \item $F(1) = 2F(0)$.
  \item $F(1)F(0) = 0$.
  \end{enumerate}

  \vspace{0.05in}
  Your answer: $\underline{\qquad\qquad\qquad\qquad\qquad\qquad\qquad}$
  \vspace{0.05in}

\item Suppose $F$ is a function defined on $\R \setminus \{ 0 \}$ such
  that $F'(x) = -1/x^2$ for all $x \in \R \setminus \{ 0 \}$. Which of
  the following pieces of information is/are {\bf sufficient} to determine
  $F$ completely? Please see options (D) and (E) before answering.

  \begin{enumerate}[(A)]
  \item The value of $F$ at any two positive numbers.
  \item The value of $F$ at any two negative numbers.
  \item The value of $F$ at a positive number and a negative number.
  \item Any of the above pieces of information is sufficient, i.e., we
    need to know the value of $F$ at any two numbers.
  \item None of the above pieces of information is sufficient.
  \end{enumerate}

  \vspace{0.05in}
  Your answer: $\underline{\qquad\qquad\qquad\qquad\qquad\qquad\qquad}$
  \vspace{0.05in}

\item Suppose $F,G$ are continuously differentiable functions defined
  on all of $\R$. Suppose $a,b$ are real numbers with $a <
  b$. Suppose, further, that $G(x)$ is identically zero everywhere
  except on the open interval $(a,b)$. Then, what can we say about the
  relationship between the numbers $P = \int_a^b F(x)G'(x) \,dx$ and
  $Q = \int_a^b F'(x)G(x) \, dx$?

  \begin{enumerate}[(A)]
  \item $P = Q$
  \item $P = -Q$
  \item $PQ = 0$
  \item $P = 1 - Q$
  \item $PQ = 1$
  \end{enumerate}

  \vspace{0.05in}
  Your answer: $\underline{\qquad\qquad\qquad\qquad\qquad\qquad\qquad}$
  \vspace{0.05in}

\item Consider the integration $\int p(x) q''(x) \,
  dx$. Apply integration by parts twice, first taking
  $p$ as the part to differentiate, and $q$ as
  the part to integrate, and then again apply integration by parts to
  avoid a circular trap. What can we conclude?

  \begin{enumerate}[(A)]
  \item $\int p(x) q''(x) \, dx = \int p''(x) q(x) \, dx$
  \item $\int p(x) q''(x) \, dx = \int p'(x) q'(x) \, dx - \int p''(x) q(x) \, dx$
  \item $\int p(x)q''(x) \,dx = p'(x)q'(x) - \int p''(x) q(x)\, dx$
  \item $\int p(x)q''(x) \,dx = p(x)q'(x) - p'(x)q(x) + \int p''(x) q(x)\, dx$
  \item $\int p(x)q''(x) \,dx = p(x)q'(x) - p'(x)q(x) - \int p''(x) q(x)\, dx$
  \end{enumerate}

  \vspace{0.05in}
  Your answer: $\underline{\qquad\qquad\qquad\qquad\qquad\qquad\qquad}$
  \vspace{0.05in}

\item Suppose $p$ is a polynomial function. In order to
  find the indefinite integral for a function of the form $x
  \mapsto p(x)\exp(x)$, the general strategy, which always
  works, is to take $p(x)$ as the part to differentiate and
  $\exp(x)$ as the part to integrate, and keep repeating
  the process. Which of the following is the best explanation for why
  this strategy works?

  \begin{enumerate}[(A)]
  \item $\exp$ can be repeatedly differentiated (staying $\exp$) and
    polynomials can be repeatedly integrated (giving polynomials all
    the way).
  \item $\exp$ can be repeatedly integrated (staying $\exp$) and
    polynomials can be repeatedly differentiated, eventually becoming
    zero.
  \item $\exp$ and polynomials can both be repeatedly differentiated.
  \item $\exp$ and polynomials can both be repeatedly integrated.
  \item We need to use the recursive version of integration by parts
    whereby the original integrand reappears after a certain number of
    applications of integration by parts (i.e., the polynomial equals
    one of its higher derivatives, up to sign and scaling).
  \end{enumerate}

  \vspace{0.05in}
  Your answer: $\underline{\qquad\qquad\qquad\qquad\qquad\qquad\qquad}$
  \vspace{0.05in}

\item Consider the function $x \mapsto \exp(x) \sin
  x$. This function can be integrated using integration by
  parts. What can we say about how integration by parts works?

  \begin{enumerate}[(A)]
  \item We choose $\exp$ as the part to integrate and $\sin$ as the
    part to differentiate, and apply this process once to get the
    answer directly.
  \item We choose $\exp$ as the part to integrate and $\sin$ as the
    part to differentiate, and apply this process once, then use a
    {\em recursive} method (identify the integrals on the left and
    right side) to get the answer.
  \item We choose $\exp$ as the part to integrate and $\sin$ as the
    part to differentiate, and apply this process twice to get the
    answer directly.
  \item We choose $\exp$ as the part to integrate and $\sin$ as the
    part to differentiate, and apply this process twice, then use a
    {\em recursive} method (identify the integrals on the left and
    right side) to get the answer.
  \item We choose $\exp$ as the part to integrate and $\sin$ as the
    part to differentiate, and we apply integration by parts four
    times to get the answer directly.
  \end{enumerate}

  \vspace{0.05in}
  Your answer: $\underline{\qquad\qquad\qquad\qquad\qquad\qquad\qquad}$
  \vspace{0.05in}

\item Suppose $f$ is a continuous function on all of $\R$ and is the
  third derivative of an elementarily expressible function, but is not
  the fourth derivative of any elementarily expressible function. In
  other words, $f$ can be integrated three times but not four times
  within the collection of elementarily expressible functions. What is
  the {\bf largest positive integer} $k$ such that $x \mapsto x^kf(x)$
  is {\em guaranteed to be} {\bf elementarily integrable}?

  \begin{enumerate}[(A)]
  \item $1$
  \item $2$
  \item $3$
  \item $4$
  \item $5$
  \end{enumerate}

  \vspace{0.05in}
  Your answer: $\underline{\qquad\qquad\qquad\qquad\qquad\qquad\qquad}$
  \vspace{0.05in}

\item Suppose $f$ is a continuous function on $(0,\infty)$ and is the
  third derivative of an elementarily expressible function, but is not
  the fourth derivative of any elementarily expressible function. In
  other words, $f$ can be integrated three times but not four times
  within the collection of elementarily expressible functions. What is
  the {\bf largest positive integer} $k$ such that the function $x
  \mapsto f(x^{1/k})$ with domain $(0,\infty)$ is {\em guaranteed to
  be} {\bf elementarily integrable}?

  \begin{enumerate}[(A)]
  \item $1$
  \item $2$
  \item $3$
  \item $4$
  \item $5$
  \end{enumerate}

  \vspace{0.05in}
  Your answer: $\underline{\qquad\qquad\qquad\qquad\qquad\qquad\qquad}$
  \vspace{0.05in}

  
\item Of these five functions, four of the functions are elementarily
  integrable and can be integrated using integration by parts. The
  other one function is {\bf not elementarily integrable}. Identify
  this function.

  \begin{enumerate}[(A)]
  \item $x \mapsto x \sin x$
  \item $x \mapsto x \cos x$
  \item $x \mapsto x \tan x$
  \item $x \mapsto x \sin^2x$
  \item $x \mapsto x \tan^2x$
  \end{enumerate}

  \vspace{0.05in}
  Your answer: $\underline{\qquad\qquad\qquad\qquad\qquad\qquad\qquad}$
  \vspace{0.05in}

\item Consider the four functions $f_1(x) = \sqrt{\sin x}$, $f_2(x) =
  \sin \sqrt{x}$, $f_3(x) = \sin^2 x$ and $f_4(x) = \sin(x^2)$, all
  viewed as functions on the interval $[0,1]$ (so they are all well
  defined). Two of these functions are elementarily integrable; the
  other two are not. Which are {\bf the two elementarily integrable
  functions}?

  \begin{enumerate}[(A)]
  \item $f_3$ and $f_4$.
  \item $f_1$ and $f_3$.
  \item $f_1$ and $f_4$. 
  \item $f_2$ and $f_3$.
  \item $f_2$ and $f_4$.
  \end{enumerate}

  \vspace{0.05in}
  Your answer: $\underline{\qquad\qquad\qquad\qquad\qquad\qquad\qquad}$
  \vspace{0.05in}

\item Which of the following functions has an antiderivative that is
  {\bf not equivalent} up to elementary functions to the antiderivative of
  $x \mapsto e^{-x^2}$?

  \begin{enumerate}[(A)]
  \item $x \mapsto e^{-x^4}$
  \item $x \mapsto e^{-x^{2/3}}$
  \item $x \mapsto e^{-x^{2/5}}$
  \item $x \mapsto x^2e^{-x^2}$
  \item $x \mapsto x^4e^{-x^2}$
  \end{enumerate}

  \vspace{0.05in}
  Your answer: $\underline{\qquad\qquad\qquad\qquad\qquad\qquad\qquad}$
  \vspace{0.05in}

\item Consider the statements $P$ and $Q$, where $P$ states that every
  rational function is elementarily integrable, and $Q$ states that
  any rational function is $k$ times elementarily integrable for all
  positive integers $k$.

  Which of the following additional observations is {\bf correct} and
  {\bf allows us to deduce} $Q$ given $P$?

  \begin{enumerate}[(A)]
  \item There is no way of deducing $Q$ from $P$ because $P$ is true
    and $Q$ is false.
  \item The antiderivative of a rational function can always be chosen
    to be a rational function, hence $Q$ follows from a repeated
    application of $P$.
  \item Using integration by parts, we see that repeated integration
    of a function $f$ is equivalent to integrating $f$, $f^2$, $f^3$,
    and higher powers of $f$ (the powers here are pointwise products,
    not compositions). If $f$ is a rational function, each of these is
    also a rational function. Applying $P$, each of these is
    elementarily integrable, hence $f$ is $k$ times elementarily
    integrable for all $k$.
  \item Using integration by parts, we see that repeated integration
    of a function $f$ is equivalent to integrating $f$, $f'$, $f''$,
    and higher derivatives of $f$. If $f$ is a rational function, each
    of these is also a rational function. Applying $P$, each of these
    is elementarily integrable, hence $f$ is $k$ times elementarily
    integrable for all $k$.
  \item Using integration by parts, we see that repeated integration
    of a function $f$ is equivalent to integrating each of the
    functions $f(x)$, $xf(x)$, $\dots$. If $f$ is a rational function,
    each of these is also a rational function. Applying $P$, each of
    these is elementarily integrable, hence $f$ is $k$ times
    elementarily integrable for all $k$.
  \end{enumerate}

  \vspace{0.05in}
  Your answer: $\underline{\qquad\qquad\qquad\qquad\qquad\qquad\qquad}$
  \vspace{0.05in}

\item Which of these functions of $x$ is {\em not} elementarily
  integrable?

  \begin{enumerate}[(A)]
  \item $x\sqrt{1 + x^2}$
  \item $x^2\sqrt{1 + x^2}$
  \item $x(1 + x^2)^{1/3}$
  \item $x\sqrt{1 + x^3}$
  \item $x^2\sqrt{1 + x^3}$
  \end{enumerate}

  \vspace{0.05in}
  Your answer: $\underline{\qquad\qquad\qquad\qquad\qquad\qquad\qquad}$
  \vspace{0.05in}

\item Consider the function $f(k) := \int_1^2 \frac{dx}{\sqrt{x^2 +
  k}}$. $f$ is defined for $k \in (-1,\infty)$. What can we say about
  the nature of $f$ within this interval?

  \begin{enumerate}[(A)]
  \item $f$ is increasing on the interval $(-1,\infty)$.
  \item $f$ is decreasing on the interval $(-1,\infty)$.
  \item $f$ is increasing on $(-1,0)$ and decreasing on $(0,\infty)$.
  \item $f$ is decreasing on $(-1,0)$ and increasing on $(0,\infty)$.
  \item $f$ is increasing on $(-1,0)$, decreasing on $(0,2)$, and
    increasing again on $(2,\infty)$.
  \end{enumerate}

  \vspace{0.05in}
  Your answer: $\underline{\qquad\qquad\qquad\qquad\qquad\qquad\qquad}$
  \vspace{0.05in}

\item For which of these functions of $x$ does the antiderivative
  necessarily involve {\em both} $\arctan$ {\em and} $\ln$?

  \begin{enumerate}[(A)]
  \item $1/(x + 1)$
  \item $1/(x^2 + 1)$
  \item $x/(x^2 + 1)$
  \item $x/(x^3 + 1)$
  \item $x^2/(x^3 + 1)$
  \end{enumerate}

  \vspace{0.05in}
  Your answer: $\underline{\qquad\qquad\qquad\qquad\qquad\qquad\qquad}$
  \vspace{0.05in}

\item Suppose $F$ is a (not known) function defined on $\R \setminus
  \{ -1,0,1\}$, differentiable everywhere on its domain, such that
  $F'(x) = 1/(x^3 - x)$ everywhere on $\R \setminus \{-1,0,1\}$. For
  which of the following sets of points is it true that knowing the
  value of $F$ at these points {\bf uniquely} determines $F$?

  \begin{enumerate}[(A)]
  \item $\{ -\pi, -e, 1/e,1/\pi \}$
  \item $\{ -\pi/2, -\sqrt{3}/2, 11/17,\pi^2/6 \}$
  \item $\{ -\pi^3/7,-\pi^2/6,\sqrt{13},11/2 \}$
  \item Knowing $F$ at any of the above determines the value of $F$
    uniquely.
  \item None of the above works to uniquely determine the value of
    $F$.
  \end{enumerate}

  \vspace{0.05in}
  Your answer: $\underline{\qquad\qquad\qquad\qquad\qquad\qquad\qquad}$
  \vspace{0.05in}

\item Suppose $F$ is a continuously differentiable function whose
  domain contains $(a,\infty)$ for some $a \in \R$, and $F'(x)$ is a
  rational function $p(x)/q(x)$ on the domain of $F$. Further, suppose
  that $p$ and $q$ are nonzero polynomials. Denote by $d_p$ the degree
  of $p$ and by $d_q$ the degree of $q$. Which of the following is a
  {\bf necessary and sufficient condition} to ensure that $\lim_{x \to
  \infty} F(x)$ is finite?

  \begin{enumerate}[(A)]
  \item $d_p - d_q \ge 2$
  \item $d_p - d_q \ge 1$
  \item $d_p = d_q$
  \item $d_q - d_p \ge 1$
  \item $d_q - d_p \ge 2$
  \end{enumerate}

  \vspace{0.05in}
  Your answer: $\underline{\qquad\qquad\qquad\qquad\qquad\qquad\qquad}$
  \vspace{0.05in}

  For the next two questions, build on the observation: For any
  nonconstant monic polynomial $q(x)$, there exists a finite
  collection of transcendental functions $f_1, f_2, \dots, f_r$ such
  that the antiderivative of any rational function $p(x)/q(x)$, on an
  open interval where it is defined and continuous, can be expressed
  as $g_0 + f_1g_1 + f_2g_2 + \dots + f_rg_r$ where $g_0, g_1, \dots,
  g_r$ are rational functions.

\item For the polynomial $q(x) = 1 + x^2$, what collection of $f_i$s
  works (all are written as functions of $x$)?

  \begin{enumerate}[(A)]
  \item $\arctan x$ and $\ln|x|$
  \item $\arctan x$ and $\arctan(1 + x^2)$
  \item $\ln|x|$ and $\ln(1 + x^2)$ 
  \item $\arctan x$ and $\ln(1 + x^2)$
  \item $\ln|x|$ and $\arctan(1 + x^2)$
  \end{enumerate}

  \vspace{0.05in}
  Your answer: $\underline{\qquad\qquad\qquad\qquad\qquad\qquad\qquad}$
  \vspace{0.05in}

\item For the polynomial $q(x) := 1 + x^2 + x^4$, what is the
  size of the smallest collection of $f_i$s that works?

  \begin{enumerate}[(A)]
  \item $1$
  \item $2$
  \item $3$
  \item $4$
  \item $5$
  \end{enumerate}

  \vspace{0.05in}
  Your answer: $\underline{\qquad\qquad\qquad\qquad\qquad\qquad\qquad}$
  \vspace{0.05in}

\end{enumerate}

\end{document}
